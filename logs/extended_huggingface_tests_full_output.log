test_atlasia_darija_english (tests.unified_tests.extended_test_huggingface_datasets.ExtendedTestHuggingFaceDatasets.test_atlasia_darija_english) ... ok
test_bounhar_english_to_moroccan_darija (tests.unified_tests.extended_test_huggingface_datasets.ExtendedTestHuggingFaceDatasets.test_bounhar_english_to_moroccan_darija) ... ok
test_imomayiz_darija_english (tests.unified_tests.extended_test_huggingface_datasets.ExtendedTestHuggingFaceDatasets.test_imomayiz_darija_english) ... ok
test_load_and_preprocess_datasets (tests.unified_tests.extended_test_huggingface_datasets.ExtendedTestHuggingFaceDatasets.test_load_and_preprocess_datasets) ... 
  test_load_and_preprocess_datasets (tests.unified_tests.extended_test_huggingface_datasets.ExtendedTestHuggingFaceDatasets.test_load_and_preprocess_datasets) (subset='doda') ... FAIL
  test_load_and_preprocess_datasets (tests.unified_tests.extended_test_huggingface_datasets.ExtendedTestHuggingFaceDatasets.test_load_and_preprocess_datasets) (subset='transliteration') ... FAIL
test_mad_darija_bridge (tests.unified_tests.extended_test_huggingface_datasets.ExtendedTestHuggingFaceDatasets.test_mad_darija_bridge) ... ok

======================================================================
FAIL: test_load_and_preprocess_datasets (tests.unified_tests.extended_test_huggingface_datasets.ExtendedTestHuggingFaceDatasets.test_load_and_preprocess_datasets) (subset='doda')
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/mnt/c/Users/mrdbo/Documents/ReactDev/AWS/ec2/translation-service/tests/unified_tests/extended_test_huggingface_datasets.py", line 107, in test_load_and_preprocess_datasets
    tokenized_dataset = self.raw_datasets[subset]["train"].map(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mrdbo/miniconda3/envs/dataset_test_deploy_ec2/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 560, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mrdbo/miniconda3/envs/dataset_test_deploy_ec2/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3055, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/mrdbo/miniconda3/envs/dataset_test_deploy_ec2/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3458, in _map_single
    batch = apply_function_on_filtered_inputs(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mrdbo/miniconda3/envs/dataset_test_deploy_ec2/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3320, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/Users/mrdbo/Documents/ReactDev/AWS/ec2/translation-service/tests/unified_tests/extended_test_huggingface_datasets.py", line 108, in <lambda>
    lambda x: self.preprocess_function(x, subset),
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/Users/mrdbo/Documents/ReactDev/AWS/ec2/translation-service/tests/unified_tests/extended_test_huggingface_datasets.py", line 77, in preprocess_function
    labels = [self.tokenizer.encode(text, add_special_tokens=True, max_length=max_target_length, truncation=True, padding='max_length') for text in target_text]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/Users/mrdbo/Documents/ReactDev/AWS/ec2/translation-service/tests/unified_tests/extended_test_huggingface_datasets.py", line 77, in <listcomp>
    labels = [self.tokenizer.encode(text, add_special_tokens=True, max_length=max_target_length, truncation=True, padding='max_length') for text in target_text]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mrdbo/miniconda3/envs/dataset_test_deploy_ec2/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2788, in encode
    encoded_inputs = self.encode_plus(
                     ^^^^^^^^^^^^^^^^^
  File "/home/mrdbo/miniconda3/envs/dataset_test_deploy_ec2/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 3207, in encode_plus
    return self._encode_plus(
           ^^^^^^^^^^^^^^^^^^
  File "/home/mrdbo/miniconda3/envs/dataset_test_deploy_ec2/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py", line 603, in _encode_plus
    batched_output = self._batch_encode_plus(
                     ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mrdbo/miniconda3/envs/dataset_test_deploy_ec2/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py", line 529, in _batch_encode_plus
    encodings = self._tokenizer.encode_batch(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/c/Users/mrdbo/Documents/ReactDev/AWS/ec2/translation-service/tests/unified_tests/extended_test_huggingface_datasets.py", line 118, in test_load_and_preprocess_datasets
    self.fail(f"Failed to process dataset {subset}: {e}")
AssertionError: Failed to process dataset doda: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]

======================================================================
FAIL: test_load_and_preprocess_datasets (tests.unified_tests.extended_test_huggingface_datasets.ExtendedTestHuggingFaceDatasets.test_load_and_preprocess_datasets) (subset='transliteration')
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/mrdbo/miniconda3/envs/dataset_test_deploy_ec2/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3458, in _map_single
    batch = apply_function_on_filtered_inputs(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mrdbo/miniconda3/envs/dataset_test_deploy_ec2/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3320, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/Users/mrdbo/Documents/ReactDev/AWS/ec2/translation-service/tests/unified_tests/extended_test_huggingface_datasets.py", line 108, in <lambda>
    lambda x: self.preprocess_function(x, subset),
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/Users/mrdbo/Documents/ReactDev/AWS/ec2/translation-service/tests/unified_tests/extended_test_huggingface_datasets.py", line 59, in preprocess_function
    darija_col, english_col = self.get_column_names(subset)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/c/Users/mrdbo/Documents/ReactDev/AWS/ec2/translation-service/tests/unified_tests/extended_test_huggingface_datasets.py", line 51, in get_column_names
    english_col = next(col for col in required_columns if col in self.config['column_types']['english'])
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
StopIteration

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/mnt/c/Users/mrdbo/Documents/ReactDev/AWS/ec2/translation-service/tests/unified_tests/extended_test_huggingface_datasets.py", line 107, in test_load_and_preprocess_datasets
    tokenized_dataset = self.raw_datasets[subset]["train"].map(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mrdbo/miniconda3/envs/dataset_test_deploy_ec2/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 560, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mrdbo/miniconda3/envs/dataset_test_deploy_ec2/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 3055, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
RuntimeError: generator raised StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/c/Users/mrdbo/Documents/ReactDev/AWS/ec2/translation-service/tests/unified_tests/extended_test_huggingface_datasets.py", line 118, in test_load_and_preprocess_datasets
    self.fail(f"Failed to process dataset {subset}: {e}")
AssertionError: Failed to process dataset transliteration: generator raised StopIteration

----------------------------------------------------------------------
Ran 5 tests in 119.029s

FAILED (failures=2)
